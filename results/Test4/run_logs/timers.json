{
    "name": "root",
    "gauges": {
        "PacManAgent.Policy.Entropy.mean": {
            "value": 1.3562158346176147,
            "min": 1.2823816537857056,
            "max": 1.385683298110962,
            "count": 98
        },
        "PacManAgent.Policy.Entropy.sum": {
            "value": 13567.5830078125,
            "min": 12171.326171875,
            "max": 14889.3359375,
            "count": 98
        },
        "PacManAgent.Step.mean": {
            "value": 979978.0,
            "min": 9999.0,
            "max": 979978.0,
            "count": 98
        },
        "PacManAgent.Step.sum": {
            "value": 979978.0,
            "min": 9999.0,
            "max": 979978.0,
            "count": 98
        },
        "PacManAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.14936429262161255,
            "min": -0.2201058268547058,
            "max": 0.768363356590271,
            "count": 98
        },
        "PacManAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": -29.872859954833984,
            "min": -44.24127197265625,
            "max": 154.4410400390625,
            "count": 98
        },
        "PacManAgent.Policy.CuriosityValueEstimate.mean": {
            "value": 0.05489910766482353,
            "min": -0.1816861480474472,
            "max": 0.15895912051200867,
            "count": 98
        },
        "PacManAgent.Policy.CuriosityValueEstimate.sum": {
            "value": 10.97982120513916,
            "min": -36.518917083740234,
            "max": 31.791824340820312,
            "count": 98
        },
        "PacManAgent.Environment.EpisodeLength.mean": {
            "value": 150.16923076923078,
            "min": 146.76119402985074,
            "max": 190.05769230769232,
            "count": 98
        },
        "PacManAgent.Environment.EpisodeLength.sum": {
            "value": 9761.0,
            "min": 9108.0,
            "max": 10803.0,
            "count": 98
        },
        "PacManAgent.Environment.CumulativeReward.mean": {
            "value": -0.23661538468530544,
            "min": -0.26119402985074625,
            "max": 0.09115384268359496,
            "count": 98
        },
        "PacManAgent.Environment.CumulativeReward.sum": {
            "value": -15.380000004544854,
            "min": -17.5,
            "max": 4.739999819546938,
            "count": 98
        },
        "PacManAgent.Policy.ExtrinsicReward.mean": {
            "value": -0.23661538468530544,
            "min": -0.26119402985074625,
            "max": 0.09115384268359496,
            "count": 98
        },
        "PacManAgent.Policy.ExtrinsicReward.sum": {
            "value": -15.380000004544854,
            "min": -17.5,
            "max": 4.739999819546938,
            "count": 98
        },
        "PacManAgent.Policy.CuriosityReward.mean": {
            "value": 0.07611867289882726,
            "min": 0.003936655035752612,
            "max": 0.32285020220273686,
            "count": 98
        },
        "PacManAgent.Policy.CuriosityReward.sum": {
            "value": 4.947713738423772,
            "min": 0.26769254243117757,
            "max": 20.016712536569685,
            "count": 98
        },
        "PacManAgent.Losses.PolicyLoss.mean": {
            "value": 0.2323212198757877,
            "min": 0.18861113761086018,
            "max": 0.2941366767510772,
            "count": 98
        },
        "PacManAgent.Losses.PolicyLoss.sum": {
            "value": 0.2323212198757877,
            "min": 0.18861113761086018,
            "max": 0.5500824681910066,
            "count": 98
        },
        "PacManAgent.Losses.ValueLoss.mean": {
            "value": 0.0017472062080438869,
            "min": 0.0012041011528102293,
            "max": 0.04941652288349966,
            "count": 98
        },
        "PacManAgent.Losses.ValueLoss.sum": {
            "value": 0.0017472062080438869,
            "min": 0.0012041011528102293,
            "max": 0.04941652288349966,
            "count": 98
        },
        "PacManAgent.Policy.LearningRate.mean": {
            "value": 7.98369733879999e-06,
            "min": 7.98369733879999e-06,
            "max": 0.00029757360080880004,
            "count": 98
        },
        "PacManAgent.Policy.LearningRate.sum": {
            "value": 7.98369733879999e-06,
            "min": 7.98369733879999e-06,
            "max": 0.0005735256088247998,
            "count": 98
        },
        "PacManAgent.Policy.Epsilon.mean": {
            "value": 0.10266120000000001,
            "min": 0.10266120000000001,
            "max": 0.19919119999999998,
            "count": 98
        },
        "PacManAgent.Policy.Epsilon.sum": {
            "value": 0.10266120000000001,
            "min": 0.10266120000000001,
            "max": 0.39117519999999995,
            "count": 98
        },
        "PacManAgent.Policy.Beta.mean": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 98
        },
        "PacManAgent.Policy.Beta.sum": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.010000000000000002,
            "count": 98
        },
        "PacManAgent.Losses.CuriosityForwardLoss.mean": {
            "value": 0.02588719755100707,
            "min": 0.0016009143359648685,
            "max": 0.2769008943190177,
            "count": 98
        },
        "PacManAgent.Losses.CuriosityForwardLoss.sum": {
            "value": 0.02588719755100707,
            "min": 0.0016009143359648685,
            "max": 0.2769008943190177,
            "count": 98
        },
        "PacManAgent.Losses.CuriosityInverseLoss.mean": {
            "value": 1.1095875302950542,
            "min": 1.0679794023434321,
            "max": 1.3858358124891916,
            "count": 98
        },
        "PacManAgent.Losses.CuriosityInverseLoss.sum": {
            "value": 1.1095875302950542,
            "min": 1.0679794023434321,
            "max": 2.770351628462474,
            "count": 98
        },
        "PacManAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 98
        },
        "PacManAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 98
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1709134273",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Daniel\\anaconda3\\envs\\mlagents\\Scripts\\mlagents-learn config/PacManAgent.yaml --run-id=Test4 --width=350 --height=400",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.13.1+cu117",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1709137789"
    },
    "total": 3515.6592844000006,
    "count": 1,
    "self": 0.10513210000135587,
    "children": {
        "run_training.setup": {
            "total": 0.27115929999854416,
            "count": 1,
            "self": 0.27115929999854416
        },
        "TrainerController.start_learning": {
            "total": 3515.2829930000007,
            "count": 1,
            "self": 10.91427530081637,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.684627400001773,
                    "count": 1,
                    "self": 7.684627400001773
                },
                "TrainerController.advance": {
                    "total": 3496.569778299181,
                    "count": 354276,
                    "self": 4.274768497762125,
                    "children": {
                        "env_step": {
                            "total": 3492.295009801419,
                            "count": 354276,
                            "self": 397.4854181001756,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 3087.67320740184,
                                    "count": 986826,
                                    "self": 56.91830590506652,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 3030.7549014967735,
                                            "count": 980539,
                                            "self": 3030.7549014967735
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 7.136384299403289,
                                    "count": 354275,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 14020.52866530087,
                                            "count": 986822,
                                            "is_parallel": true,
                                            "self": 12264.89288640039,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0018641999995452352,
                                                    "count": 4,
                                                    "is_parallel": true,
                                                    "self": 0.0006416000032913871,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.001222599996253848,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.001222599996253848
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1755.63391470048,
                                                    "count": 986822,
                                                    "is_parallel": true,
                                                    "self": 62.77963140248539,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 50.37963899756505,
                                                            "count": 986822,
                                                            "is_parallel": true,
                                                            "self": 50.37963899756505
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1455.0128861994126,
                                                            "count": 986822,
                                                            "is_parallel": true,
                                                            "self": 1455.0128861994126
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 187.46175810101704,
                                                            "count": 986822,
                                                            "is_parallel": true,
                                                            "self": 88.68372990048738,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 98.77802820052966,
                                                                    "count": 1973644,
                                                                    "is_parallel": true,
                                                                    "self": 98.77802820052966
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.80000019504223e-05,
                    "count": 1,
                    "self": 3.80000019504223e-05,
                    "children": {
                        "thread_root": {
                            "total": 0.0,
                            "count": 0,
                            "is_parallel": true,
                            "self": 0.0,
                            "children": {
                                "trainer_advance": {
                                    "total": 3504.9110756001937,
                                    "count": 195409,
                                    "is_parallel": true,
                                    "self": 9.518685300165089,
                                    "children": {
                                        "process_trajectory": {
                                            "total": 2966.7593293000027,
                                            "count": 195409,
                                            "is_parallel": true,
                                            "self": 2962.180426099996,
                                            "children": {
                                                "RLTrainer._checkpoint": {
                                                    "total": 4.578903200006607,
                                                    "count": 39,
                                                    "is_parallel": true,
                                                    "self": 4.578903200006607
                                                }
                                            }
                                        },
                                        "_update_policy": {
                                            "total": 528.6330610000259,
                                            "count": 121,
                                            "is_parallel": true,
                                            "self": 234.02856490005433,
                                            "children": {
                                                "TorchPPOOptimizer.update": {
                                                    "total": 294.6044960999716,
                                                    "count": 7260,
                                                    "is_parallel": true,
                                                    "self": 294.6044960999716
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.11427399999956833,
                    "count": 1,
                    "self": 0.0026928999977826606,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.11158110000178567,
                            "count": 1,
                            "self": 0.11158110000178567
                        }
                    }
                }
            }
        }
    }
}